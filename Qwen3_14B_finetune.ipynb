{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb5cfea2",
   "metadata": {},
   "source": [
    "# Qwen3-14B ä¸­æ–‡æŒ‡ä»¤å¾®è°ƒä»£ç ä¸åŸç†é€æ­¥è¯¦è§£\n",
    "\n",
    "æœ¬ notebook ç»“åˆä»£ç å’Œè¯¦ç»†æ³¨é‡Šï¼Œé€æ­¥è®²è§£ Qwen3-14B ä¸­æ–‡æŒ‡ä»¤å¾®è°ƒçš„å®Œæ•´æµç¨‹ï¼Œå¸®åŠ©ä½ ç†è§£æ¯ä¸€æ­¥çš„ä½œç”¨å’ŒèƒŒåæœºåˆ¶ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b1f9f0",
   "metadata": {},
   "source": [
    "## 1. å®‰è£…ä¾èµ–ä¸ç¯å¢ƒå‡†å¤‡\n",
    "\n",
    "åœ¨å¾®è°ƒå¤§æ¨¡å‹å‰ï¼Œéœ€è¦å‡†å¤‡å¥½åˆé€‚çš„ç¡¬ä»¶å’Œè½¯ä»¶ç¯å¢ƒï¼Œå¹¶å®‰è£…ç›¸å…³ä¾èµ–åŒ…ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d7716f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®‰è£…æ‰€æœ‰å¿…è¦çš„ä¾èµ–åŒ…\n",
    "# unsloth: é«˜æ•ˆå¤§æ¨¡å‹å¾®è°ƒå·¥å…·\n",
    "# bitsandbytes: æ”¯æŒ8bit/4bité‡åŒ–ï¼ŒèŠ‚çœæ˜¾å­˜\n",
    "# accelerate: åˆ†å¸ƒå¼è®­ç»ƒå’Œæ¨ç†åŠ é€Ÿ\n",
    "# xformers: é«˜æ•ˆTransformeråŠ é€Ÿåº“\n",
    "# peft: å‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆå¦‚LoRAï¼‰æ ¸å¿ƒåº“\n",
    "# trl: HuggingFaceæŒ‡ä»¤å¾®è°ƒè®­ç»ƒåº“\n",
    "# datasets: æ•°æ®é›†åŠ è½½å’Œå¤„ç†\n",
    "# å…¶ä»–å¦‚sentencepieceã€protobufã€huggingface_hubã€hf_transferç­‰\n",
    "!pip install unsloth bitsandbytes accelerate xformers==0.0.29.post3 peft trl triton cut_cross_entropy unsloth_zoo sentencepiece protobuf 'datasets>=3.4.1,<4.0.0' 'huggingface_hub>=0.34.0' hf_transfer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc8d7ce",
   "metadata": {},
   "source": [
    "## 2. åŠ è½½ Qwen3-14B åŸºç¡€æ¨¡å‹\n",
    "\n",
    "æœ¬èŠ‚å°†åŠ è½½ Qwen3-14B åŸºç¡€æ¨¡å‹ï¼Œå¹¶ä»‹ç»ç›¸å…³å‚æ•°çš„ä½œç”¨ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fca99e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiaoke/miniconda3/envs/unsloth/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2025.7.11: Fast Qwen3 patching. Transformers: 4.54.1.\n",
      "   \\\\   /|    NVIDIA RTX A6000. Num GPUs = 1. Max memory: 44.988 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.6. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:08<00:00,  2.75s/it]\n"
     ]
    }
   ],
   "source": [
    "# å¯¼å…¥ FastLanguageModel å’Œ torch\n",
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "\n",
    "# è®¾ç½®æœ€å¤§åºåˆ—é•¿åº¦ï¼Œå½±å“æ¨¡å‹ä¸€æ¬¡èƒ½å¤„ç†çš„æœ€å¤§tokenæ•°\n",
    "max_seq_length = 2048\n",
    "# è‡ªåŠ¨æ£€æµ‹æ•°æ®ç±»å‹ï¼ˆfloat16/bfloat16/float32ï¼‰ï¼Œå½±å“æ˜¾å­˜å’Œé€Ÿåº¦\n",
    "dtype = None\n",
    "# æ˜¯å¦ä½¿ç”¨4bité‡åŒ–ä»¥èŠ‚çœæ˜¾å­˜\n",
    "load_in_4bit = True\n",
    "\n",
    "# åŠ è½½ Qwen3-14B åŸºç¡€æ¨¡å‹å’Œåˆ†è¯å™¨\n",
    "# model_name æŒ‡å®šæ¨¡å‹æƒé‡æ¥æº\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = 'unsloth/Qwen3-14B-Base-unsloth-bnb-4bit',\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    ")\n",
    "# 4bité‡åŒ–èƒ½å¤§å¹…é™ä½å¤§æ¨¡å‹çš„æ˜¾å­˜éœ€æ±‚ï¼Œä½¿æ¶ˆè´¹çº§æ˜¾å¡ä¹Ÿèƒ½è¿è¡Œ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c435449",
   "metadata": {},
   "source": [
    "## 3. æ·»åŠ  LoRA é€‚é…å™¨ï¼ˆå‚æ•°é«˜æ•ˆå¾®è°ƒï¼‰\n",
    "\n",
    "LoRAï¼ˆLow-Rank Adaptationï¼‰æ˜¯ä¸€ç§å‚æ•°é«˜æ•ˆå¾®è°ƒæ–¹æ³•ï¼Œåªéœ€è®­ç»ƒæå°‘é‡æ–°å¢å‚æ•°å³å¯è·å¾—è‰¯å¥½æ•ˆæœã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f545363",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.7.11 patched 40 layers with 40 QKV layers, 40 O layers and 40 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "# ä½¿ç”¨ LoRA åªå¾®è°ƒéƒ¨åˆ†å‚æ•°ï¼ŒèŠ‚çœæ˜¾å­˜å’Œè®¡ç®—èµ„æº\n",
    "# r: LoRAç§©ï¼Œè¶Šå¤§å¯å­¦ä¹ èƒ½åŠ›è¶Šå¼ºï¼Œæ˜¾å­˜æ¶ˆè€—ä¹Ÿè¶Šå¤§\n",
    "# target_modules: éœ€è¦æ³¨å…¥LoRAçš„æ¨¡å— \n",
    "# q_proj, k_proj, v_proj, o_projï¼šåˆ†åˆ«æ˜¯æ³¨æ„åŠ›æœºåˆ¶ä¸­çš„ Queryã€Keyã€Value å’Œè¾“å‡ºæŠ•å½±å±‚ã€‚\n",
    "# gate_proj, up_proj, down_projï¼šæ˜¯å‰é¦ˆç½‘ç»œï¼ˆFFNï¼‰ä¸­çš„é—¨æ§ã€ä¸ŠæŠ•å½±å’Œä¸‹æŠ•å½±å±‚ã€‚\n",
    "# lora_alpha: LoRAç¼©æ”¾å› å­\n",
    "# lora_dropout: LoRA dropoutï¼Œ0è¡¨ç¤ºä¸ä¸¢å¼ƒ\n",
    "# bias: ä¸è®­ç»ƒbias\n",
    "# use_gradient_checkpointing: èŠ‚çœæ˜¾å­˜\n",
    "# random_state: éšæœºç§å­ï¼Œä¿è¯å¯å¤ç°\n",
    "# use_rslora/loftq_config: è¿›é˜¶å‚æ•°\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16,\n",
    "    target_modules = ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj'],\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0,\n",
    "    bias = 'none',\n",
    "    use_gradient_checkpointing = 'unsloth',\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,\n",
    "    loftq_config = None,\n",
    ")\n",
    "# LoRAåªéœ€è®­ç»ƒæå°‘é‡æ–°å¢å‚æ•°ï¼Œæå¤§é™ä½èµ„æºæ¶ˆè€—"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a961979",
   "metadata": {},
   "source": [
    "## 4. æ•°æ®å‡†å¤‡ä¸ Prompt æ ¼å¼åŒ–\n",
    "\n",
    "æœ¬èŠ‚å°†ä»‹ç»å¦‚ä½•å‡†å¤‡æŒ‡ä»¤å¾®è°ƒæ•°æ®ï¼Œå¹¶å°†å…¶æ ¼å¼åŒ–ä¸ºé€‚åˆæ¨¡å‹è®­ç»ƒçš„ prompt æ ¼å¼ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85ffb2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®šä¹‰ä¸­æ–‡ Alpaca prompt æ¨¡æ¿ï¼Œç»Ÿä¸€æ ¼å¼ä¾¿äºæ¨¡å‹å­¦ä¹ æŒ‡ä»¤è·Ÿéšèƒ½åŠ›\n",
    "alpaca_prompt = '''ä¸‹é¢æ˜¯ä¸€ä¸ªä»»åŠ¡æŒ‡ä»¤ï¼Œé…æœ‰è¿›ä¸€æ­¥çš„è¾“å…¥ä¿¡æ¯ï¼Œè¯·å†™å‡ºä¸€ä¸ªåˆç†çš„å®Œæˆè¯¥ä»»åŠ¡çš„å›å¤ã€‚\n",
    "\n",
    "### æŒ‡ä»¤:\n",
    "{}\n",
    "\n",
    "### è¾“å…¥:\n",
    "{}\n",
    "\n",
    "### å›å¤:\n",
    "{}'''\n",
    "\n",
    "# è·å–åˆ†è¯å™¨çš„ EOSï¼ˆç»“æŸï¼‰æ ‡è®°ï¼Œå¸®åŠ©æ¨¡å‹åŒºåˆ†æ ·æœ¬\n",
    "EOS_TOKEN = tokenizer.eos_token\n",
    "\n",
    "# æ ¼å¼åŒ–æ•°æ®é›†ä¸º prompt æ ¼å¼\n",
    "# å°†åŸå§‹ä¸‰å…ƒç»„æ‹¼æ¥ä¸ºç»Ÿä¸€æ–‡æœ¬ï¼Œä¾¿äºæ¨¡å‹è®­ç»ƒ\n",
    "def formatting_prompts_func(examples):\n",
    "    instructions = examples['instruction']\n",
    "    inputs = examples['input']\n",
    "    outputs = examples['output']\n",
    "    texts = []\n",
    "    for instruction, input, output in zip(instructions, inputs, outputs):\n",
    "        text = alpaca_prompt.format(instruction, input, output) + EOS_TOKEN\n",
    "        texts.append(text)\n",
    "    return { 'text': texts }\n",
    "\n",
    "# åŠ è½½ Alpaca ä¸­æ–‡æ•°æ®é›†ï¼ˆ52Kæ¡æŒ‡ä»¤-è¾“å…¥-è¾“å‡ºæ ·æœ¬ï¼‰\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset('yahma/alpaca-cleaned', split='train')\n",
    "# åº”ç”¨æ ¼å¼åŒ–å‡½æ•°ï¼Œå¾—åˆ°æœ€ç»ˆå¯è®­ç»ƒæ•°æ®\n",
    "dataset = dataset.map(formatting_prompts_func, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e654ebd",
   "metadata": {},
   "source": [
    "## 5. å¼€å§‹è®­ç»ƒ\n",
    "\n",
    "æœ¬èŠ‚å°†ä½¿ç”¨ SFTTrainer è¿›è¡ŒæŒ‡ä»¤å¾®è°ƒï¼Œå¹¶è§£é‡Šä¸»è¦è®­ç»ƒå‚æ•°çš„ä½œç”¨ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dfde36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 51,760 | Num Epochs = 1 | Total steps = 60\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
      " \"-____-\"     Trainable parameters = 64,225,280 of 14,832,532,480 (0.43% trained)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [60/60 03:51, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.347000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.810600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.471400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.678400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.519800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.429700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.233500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.124800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.017100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.808700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.848200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.770100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.981200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.762600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.731000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.878200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.234600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.900700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.732200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.803100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.878200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.883200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.893100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.965900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.915900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.959300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.811400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.855600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.702200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.784000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.759700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.918300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.761900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.869500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.767600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.742600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.662400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.975800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.987200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.826900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.862500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.809900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.826400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.916500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.851300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.708600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>1.130400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.767100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.980800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.937200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.806000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.908200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>1.032400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.696500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.918100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.772400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.699800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.743400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.833200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# å¯¼å…¥ SFTConfig å’Œ SFTTrainer\n",
    "from trl import SFTConfig, SFTTrainer\n",
    "\n",
    "# é…ç½®å¹¶åˆå§‹åŒ– Trainer\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = dataset,\n",
    "    dataset_text_field = 'text',\n",
    "    max_seq_length = max_seq_length,\n",
    "    args = SFTConfig(\n",
    "        per_device_train_batch_size = 2,  # æ¯å¼ å¡ batch sizeï¼Œå½±å“æ˜¾å­˜å’Œé€Ÿåº¦\n",
    "        gradient_accumulation_steps = 4,  # æ¢¯åº¦ç´¯ç§¯ï¼Œç­‰æ•ˆå¢å¤§batch size\n",
    "        warmup_steps = 5,                # é¢„çƒ­æ­¥æ•°\n",
    "        max_steps = 60,                  # è®­ç»ƒæ­¥æ•°ï¼ˆå¯æ ¹æ®éœ€è¦è°ƒæ•´ï¼‰\n",
    "        learning_rate = 2e-4,            # å­¦ä¹ ç‡\n",
    "        logging_steps = 1,               # æ—¥å¿—æ‰“å°é¢‘ç‡\n",
    "        optim = 'adamw_8bit',            # ä¼˜åŒ–å™¨ï¼Œé€‚åˆå¤§æ¨¡å‹\n",
    "        weight_decay = 0.01,             # æƒé‡è¡°å‡\n",
    "        lr_scheduler_type = 'linear',    # å­¦ä¹ ç‡è°ƒåº¦\n",
    "        seed = 3407,                     # éšæœºç§å­\n",
    "        output_dir = 'model_train_outputs',          # è¾“å‡ºç›®å½•\n",
    "        report_to = 'none',              # ä¸ä¸ŠæŠ¥æ—¥å¿—\n",
    "    ),\n",
    ")\n",
    "# å¼€å§‹è®­ç»ƒ\n",
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a05a09",
   "metadata": {},
   "source": [
    "## 6. æ¨ç†æµ‹è¯•\n",
    "\n",
    "è®­ç»ƒå®Œæˆåï¼Œå¯ä»¥ç”¨å¾®è°ƒåçš„æ¨¡å‹è¿›è¡Œæ¨ç†ï¼Œæ£€éªŒå…¶æŒ‡ä»¤è·Ÿéšèƒ½åŠ›ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26384502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ä¸‹é¢æ˜¯ä¸€ä¸ªä»»åŠ¡æŒ‡ä»¤ï¼Œé…æœ‰è¿›ä¸€æ­¥çš„è¾“å…¥ä¿¡æ¯ï¼Œè¯·å†™å‡ºä¸€ä¸ªåˆç†çš„å®Œæˆè¯¥ä»»åŠ¡çš„å›å¤ã€‚\\n\\n### æŒ‡ä»¤:\\nè¯·ç»­å†™æ–æ³¢é‚£å¥‘æ•°åˆ—ã€‚\\n\\n### è¾“å…¥:\\n1, 1, 2, 3, 5, 8\\n\\n### å›å¤:\\n13, 21, 34, 55, 89, 144, 233, 377, 610, 987, 1597, 2584, 4181, 6']\n"
     ]
    }
   ],
   "source": [
    "# åˆ‡æ¢åˆ°æ¨ç†æ¨¡å¼ï¼Œæå‡æ¨ç†é€Ÿåº¦\n",
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "# æ„é€ æ¨ç†è¾“å…¥ï¼Œä½¿ç”¨ä¸è®­ç»ƒç›¸åŒçš„promptæ¨¡æ¿\n",
    "inputs = tokenizer([\n",
    "    alpaca_prompt.format(\n",
    "        'è¯·ç»­å†™æ–æ³¢é‚£å¥‘æ•°åˆ—ã€‚',\n",
    "        '1, 1, 2, 3, 5, 8',\n",
    "        ''\n",
    "    )\n",
    "], return_tensors='pt').to('cuda')\n",
    "\n",
    "# ç”Ÿæˆæ¨¡å‹è¾“å‡ºï¼Œmax_new_tokensæ§åˆ¶ç”Ÿæˆé•¿åº¦ï¼Œuse_cacheåŠ é€Ÿæ¨ç†\n",
    "outputs = model.generate(**inputs, max_new_tokens=64, use_cache=True)\n",
    "# è§£ç è¾“å‡ºå¹¶æ‰“å°\n",
    "print(tokenizer.batch_decode(outputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fea76e8",
   "metadata": {},
   "source": [
    "## 7. ä¿å­˜å¾®è°ƒåçš„æ¨¡å‹\n",
    "\n",
    "æœ€åï¼Œå°†å¾®è°ƒå¾—åˆ°çš„ LoRA æƒé‡å’Œåˆ†è¯å™¨ä¿å­˜ï¼Œä¾¿äºåç»­åŠ è½½å’Œéƒ¨ç½²ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7c0e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¿å­˜ LoRA å¾®è°ƒæƒé‡å’Œåˆ†è¯å™¨\n",
    "# åªéœ€ä¿å­˜LoRAæƒé‡ï¼Œæ–‡ä»¶ä½“ç§¯å°ï¼Œä¾¿äºåˆ†å‘å’Œéƒ¨ç½²\n",
    "model.save_pretrained('lora_model')\n",
    "tokenizer.save_pretrained('lora_model')\n",
    "# åç»­åŠ è½½æ—¶ï¼Œåªéœ€åŸºç¡€æ¨¡å‹+LoRAæƒé‡+åˆ†è¯å™¨å³å¯å¤ç°å¾®è°ƒæ•ˆæœ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
